{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Dependancies \n",
    "from transformers import pipeline\n",
    "from docx import Document\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning Text Functions\n",
    "\n",
    "def prepare(input_text_path, output_text_path, start_string, end_string):\n",
    "    doc = Document(input_text_path)\n",
    "    cleaned_text = []\n",
    "    \n",
    "    # Regular expression to match timestamps\n",
    "    timestamp_regex = re.compile(r'\\b\\d{1,2}:\\d{2}:\\d{2}\\b')\n",
    "    \n",
    "    # Flags for controlling text recording\n",
    "    start_recording = False\n",
    "    end_recording = False\n",
    "    \n",
    "    for para in doc.paragraphs:\n",
    "        if start_string in para.text:\n",
    "            start_recording = True  # Signal to start recording text from the next paragraph\n",
    "            print(\"found the start string\")\n",
    "            continue  # Skip appending the starting string\n",
    "        if end_string in para.text:\n",
    "            end_recording = True  # Signal to stop recording text\n",
    "            print(\"found the end string\")\n",
    "            break  # Exit the loop since the end string has been encountered\n",
    "        \n",
    "        if start_recording and not end_recording:\n",
    "            text = para.text\n",
    "            \n",
    "            # Remove timestamps from the text\n",
    "            text = timestamp_regex.sub(\"\", text)\n",
    "            \n",
    "            # Conditionally remove the \"R:\" prefix if present, after removing timestamps\n",
    "            if text.startswith(\"R:\"):\n",
    "                text = text[2:].strip()\n",
    "            \n",
    "            # Skip paragraphs that start with \"I:\"\n",
    "            if not text.startswith(\"I:\"):\n",
    "                cleaned_text.append(text.strip())  \n",
    "    \n",
    "    final_text = \"\\n\".join(cleaned_text)\n",
    "    \n",
    "    # Write the cleaned text to the output file\n",
    "    with open(output_text_path, 'w', encoding='utf-8') as file:\n",
    "        file.write(final_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare(input_text_path, output_text_path):\n",
    "    doc = Document(input_text_path)\n",
    "    cleaned_text = []\n",
    "    \n",
    "    # Regular expression to match timestamps\n",
    "    timestamp_regex = re.compile(r'\\b\\d{1,2}:\\d{2}:\\d{2}\\b')\n",
    "    \n",
    "    for para in doc.paragraphs:\n",
    "        text = para.text\n",
    "        \n",
    "        # Remove timestamps from the text\n",
    "        text = timestamp_regex.sub(\"\", text)\n",
    "        \n",
    "        # Conditionally remove the \"R:\" prefix if present, after removing timestamps\n",
    "        if text.startswith(\"R:\"):\n",
    "            text = text[2:].strip()\n",
    "        \n",
    "        # Skip paragraphs that start with \"I:\"\n",
    "        if not text.startswith(\"I:\"):\n",
    "            cleaned_text.append(text.strip())  \n",
    "    \n",
    "    final_text = \"\\n\".join(cleaned_text)\n",
    "    \n",
    "    # Write the cleaned text to the output file\n",
    "    with open(output_text_path, 'w', encoding='utf-8') as file:\n",
    "        file.write(final_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found the start string\n",
      "found the end string\n"
     ]
    }
   ],
   "source": [
    "# Conditional \n",
    "inputtext_conditional = \"/Users/sunmoon/Desktop/nlp/joint.docx\"\n",
    "outputtext_conditional = \"/Users/sunmoon/Desktop/nlp/joint_cleaned.txt\"\n",
    "\n",
    "prepare(inputtext_conditional,outputtext_conditional, \"Intra household discussion and Bargaining\", \"General norms around land\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found the start string\n",
      "found the end string\n"
     ]
    }
   ],
   "source": [
    "# Unconditional (wife not on deed)\n",
    "\n",
    "inputtext_unconditional = \"/Users/sunmoon/Desktop/nlp/single.docx\"\n",
    "outputtext_unconditional = \"/Users/sunmoon/Desktop/nlp/single_cleaned.txt\"\n",
    "\n",
    "prepare(inputtext_unconditional,outputtext_unconditional, \"Intra-household discussion and bargaining\", \"Gender norms around land\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFRobertaForSequenceClassification: ['roberta.embeddings.position_ids']\n",
      "- This IS expected if you are initializing TFRobertaForSequenceClassification from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFRobertaForSequenceClassification from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFRobertaForSequenceClassification were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaForSequenceClassification for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "#classifier = pipeline(\"text-classification\", model=\"j-hartmann/emotion-english-distilroberta-base\", return_all_scores=True)\n",
    "classifier = pipeline(task=\"text-classification\", model=\"SamLowe/roberta-base-go_emotions\", top_k=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[{'label': 'neutral', 'score': 0.9689276218414307}, {'label': 'approval', 'score': 0.010621764697134495}, {'label': 'annoyance', 'score': 0.0072591654025018215}, {'label': 'realization', 'score': 0.004994337912648916}, {'label': 'disapproval', 'score': 0.003861496224999428}, {'label': 'disappointment', 'score': 0.0035657351836562157}, {'label': 'admiration', 'score': 0.003407483221963048}, {'label': 'confusion', 'score': 0.0033609310630708933}, {'label': 'anger', 'score': 0.002968629589304328}, {'label': 'disgust', 'score': 0.0029220380820333958}, {'label': 'sadness', 'score': 0.0027078292332589626}, {'label': 'amusement', 'score': 0.002326824702322483}, {'label': 'excitement', 'score': 0.002281916094943881}, {'label': 'joy', 'score': 0.002070820890367031}, {'label': 'curiosity', 'score': 0.001999541651457548}, {'label': 'fear', 'score': 0.001791447284631431}, {'label': 'love', 'score': 0.0017111704219132662}, {'label': 'optimism', 'score': 0.0016817477298900485}, {'label': 'desire', 'score': 0.0013877947349101305}, {'label': 'gratitude', 'score': 0.0011813443852588534}, {'label': 'caring', 'score': 0.001103821792639792}, {'label': 'surprise', 'score': 0.001087990473024547}, {'label': 'embarrassment', 'score': 0.0008874628692865372}, {'label': 'grief', 'score': 0.0005667590303346515}, {'label': 'remorse', 'score': 0.0004355736600700766}, {'label': 'nervousness', 'score': 0.0003953523701056838}, {'label': 'pride', 'score': 0.0003651083097793162}, {'label': 'relief', 'score': 0.00035728744114749134}]]\n"
     ]
    }
   ],
   "source": [
    "# Conditional \n",
    "results_conditional = classifier(outputtext_conditional)\n",
    "print(results_conditional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[{'label': 'neutral', 'score': 0.9686564207077026}, {'label': 'approval', 'score': 0.010021964088082314}, {'label': 'annoyance', 'score': 0.0074686771258711815}, {'label': 'realization', 'score': 0.004718221258372068}, {'label': 'disapproval', 'score': 0.003920832183212042}, {'label': 'confusion', 'score': 0.0036984344478696585}, {'label': 'disappointment', 'score': 0.0033637257292866707}, {'label': 'admiration', 'score': 0.003210442140698433}, {'label': 'anger', 'score': 0.00317251100204885}, {'label': 'disgust', 'score': 0.0028084740042686462}, {'label': 'sadness', 'score': 0.0024821481201797724}, {'label': 'amusement', 'score': 0.00232497020624578}, {'label': 'excitement', 'score': 0.0022132357116788626}, {'label': 'curiosity', 'score': 0.0021854734513908625}, {'label': 'joy', 'score': 0.0019707013852894306}, {'label': 'fear', 'score': 0.001706388546153903}, {'label': 'optimism', 'score': 0.001658217515796423}, {'label': 'love', 'score': 0.0015884240856394172}, {'label': 'desire', 'score': 0.0012988217640668154}, {'label': 'gratitude', 'score': 0.0011642888421192765}, {'label': 'surprise', 'score': 0.0010963106760755181}, {'label': 'caring', 'score': 0.0010848597157746553}, {'label': 'embarrassment', 'score': 0.0008610860677435994}, {'label': 'grief', 'score': 0.000535806582774967}, {'label': 'remorse', 'score': 0.0004093978786841035}, {'label': 'nervousness', 'score': 0.0003770670446101576}, {'label': 'pride', 'score': 0.0003406791656743735}, {'label': 'relief', 'score': 0.0003291988105047494}]]\n"
     ]
    }
   ],
   "source": [
    "# Unconditional \n",
    "results_unconditional = classifier(outputtext_unconditional)\n",
    "print(results_unconditional)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
